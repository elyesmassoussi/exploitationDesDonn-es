package org.exemple.population.function.parser;

import com.esotericsoftware.minlog.Log;
import com.typesafe.config.Config;
import com.typesafe.config.ConfigFactory;
import org.apache.spark.api.java.function.MapFunction;
import org.apache.spark.api.java.function.ReduceFunction;
import org.apache.spark.sql.*;
import org.example.entities.beans.Population;
import org.example.entities.beans.Stat;
import org.example.entities.functions.MapFunctionKey;
import org.example.entities.functions.MapPopulationToStat;
import org.junit.Assert;
import org.junit.Test;
import scala.Function2;
import scala.Tuple2;

import uk.co.gresearch.spark.diff.Diff;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;

import static org.assertj.core.api.Assertions.assertThat;

public class DataSetObjectTest {

    @Test
    public void test(){

        Config config = ConfigFactory.load("application.conf");
        String masterUrl = config.getString("master");
        String appName = config.getString("appname");

        SparkSession spark = SparkSession.builder().master(masterUrl).appName(appName).getOrCreate();
        Encoder<Population> encoder = Encoders.bean(Population.class);


        List<Population> data =
                List.of(Population.builder()
                        .annee("1992")
                        .popMunicipale("568932")
                        .popComptee("01004")
                        .popTotale("35789")
                        .build() ,
        Population.builder()
                .annee("1528")
                .popMunicipale("15478")
                .popComptee("122365")
                .popTotale("15487")
                .build(),
                Population.builder()
                        .annee("1992")
                        .popMunicipale("4627")
                        .popComptee("5454")
                        .popTotale("212")
                        .build() ) ;

        Dataset<Population> dso = spark.createDataset(data,encoder);
        MapFunctionKey mfp = new MapFunctionKey() ;
        KeyValueGroupedDataset<String, Population> buckets = dso.groupByKey(mfp,
                Encoders.STRING());



        MapPopulationToStat mpts = new MapPopulationToStat() ;
        Encoder<Stat> encoderStat = Encoders.bean(Stat.class);
        KeyValueGroupedDataset<String, Stat> stringStatKeyValueGroupedDataset = buckets.mapValues(mpts, encoderStat);


        System.out.println(stringStatKeyValueGroupedDataset.toString());
        Dataset<Tuple2<String, Stat>> reduced = stringStatKeyValueGroupedDataset.reduceGroups((ReduceFunction<Stat>) (s1, s2) -> new Stat(s1.getAnnee(), s1.getCount() + s2.getCount()));

        reduced.show();

        Dataset<Stat> result =   reduced.map((MapFunction<Tuple2<String, Stat>, Stat>) t1 -> t1._2(), encoderStat);


        Stat s1 = new Stat("1992",2);
        Stat s2 = new Stat("1528",1);


        List< Stat> data2 =
                Arrays.asList( s1, s2);
        Dataset<Stat> expected = spark.createDataset(data2, encoderStat);
        expected.show();
        result.show();
        Dataset<Row> diff = Diff.of(expected,result,"annee");
        //diff.show();


        Dataset<Row> diffcount = diff.groupBy("diff").count().cache();
        //diffcount.show();

        System.out.println(result.toString());
        assertThat(diffcount.filter("diff !=N").count()).isEqualTo(0);




    }

}
